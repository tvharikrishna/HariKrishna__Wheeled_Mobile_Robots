<!------ Copyrights ------>
<p align="right">© 𝗗𝗼𝗰𝘂𝗺𝗲𝗻𝘁𝗮𝘁𝗶𝗼𝗻 𝗯𝘆 𝘁𝘃𝗵𝗮𝗿𝗶𝗸𝗿𝗶𝘀𝗵𝗻𝗮</p>
<p align="right">5 𝘮𝘪𝘯𝘶𝘵𝘦 𝘳𝘦𝘢𝘥 📚 </p> <br>

<!------ PROJECT TITLE ------>
<p align="center">
    <img src="readme_data/project_title.png" alt="project title" width="1111"/>
</p> <hr> <br>

<!------ WHAT ------>
<p align="center">
    <img src="readme_data/what.png" alt="what section" width="600"/>
</p>

<p align="center"><h1>🎀 Essence of the Project</h1></p>
<p align='justify'>
▸ This project showcases the HK Bot, an innovative custom made mobile robot engineered for autonomous navigation and proficient obstacle avoidance. It incorporates YdLidar technology for high-precision environmental scanning and leverages the Robot Operating System (ROS) to offer a sturdy and adaptable platform for robot programming. </p>

<p align='justify'>
▸ Furthermore, the system's spatial data and sensor inputs are visualized using rviz, ROS's 3D visualization tool, allowing for the plotting of 2D LiDAR points for a comprehensive understanding of the robot's perception and navigation capabilities. </p>

<p align="center">
  <a href="https://www.linkedin.com/posts/tvharikrishnahk_lidar-pointcloud-ros-activity-7074351404991008769-n0g3/?utm_source=share&utm_medium=member_desktop">
    <img src="https://img.shields.io/badge/My Project Video-Obstacle Evader Robot-blue" alt="Video" width="337" height="30"/>
  </a>
</p> <hr> <br>

<!------ WHY ------>
<p align="center">
    <img src="readme_data/why.png" alt="What the project accomplishes" width="600"/>
</p>

<p align="center"><h1>🎯 Project Vision</h1></p>
<p style="text-align: justify;">
The project is dedicated to advancing obstacle avoidance technology, a cornerstone for the safety and operational effectiveness of autonomous mobile robots and vehicles. Incorporating real-time decision-making capabilities, this project aims to enhance autonomous navigation in complex environments. Here are the key benefits that obstacle avoidance systems contribute to the field of autonomous mobility:
<br>
    
▸ <code>Essential Safety Mechanism:</code> Obstacle avoidance is vital for autonomous systems, enabling safe navigation without collisions, especially in dynamic or unpredictable settings.

▸ <code>Real-time Decision Making:</code> This technology empowers autonomous machines to instantly adapt to new obstacles, ensuring efficient and reliable task execution for services like automated delivery or emergency aid.

▸ <code>Human Intervention Reduction:</code> By leveraging obstacle avoidance, the need for human oversight decreases, pushing the boundaries in autonomous driving and contributing to fewer traffic incidents and enhanced road safety.
</p> <hr> <br>

<!------ HOW ------><!------ HOW ------><!------ HOW ------>
<p align="center">
    <img src="readme_data/how.png" alt="How we implemented the project" width="600"/>
</p>

<p align="center"><h1>🪓Project Implementation</h1></p>
<p><h2>💠 Software Design & Tools </h2></p>
<p align='justify'>
The project is developed using a robust and versatile tech stack, comprising Ubuntu and Linux for the operating systems, Python as the primary programming language, and utilizing essential tools like SSH, PuTTY, and VNC Viewer for secure remote connections. Development and simulation are enhanced with the ROS ecosystem, including RViz for visualization. </p>

<img src="https://img.shields.io/badge/Ubuntu-E95420.svg?&style=flat-square&logo=ubuntu&logoColor=white" alt="Ubuntu" style="height: 25px;"/> &nbsp;
<img src="https://img.shields.io/badge/Linux-FCC624.svg?&style=flat-square&logo=linux&logoColor=black" alt="Linux" style="height: 25px;"/> &nbsp;
<img src="https://img.shields.io/badge/Python-3776AB.svg?&style=flat-square&logo=python&logoColor=white" alt="Python" style="height: 25px;"/> &nbsp;
<img src="https://img.shields.io/badge/SSH-4D4D4D.svg?&style=flat-square&logo=windows-terminal&logoColor=white" alt="SSH" style="height: 25px;"/> &nbsp;
<img src="https://img.shields.io/badge/PuTTY-007ACC.svg?&style=flat-square&logo=windows-terminal&logoColor=white" alt="PuTTY" style="height: 25px;"/> &nbsp;
<img src="https://img.shields.io/badge/VNC%20Viewer-ED1C24.svg?&style=flat-square&logo=CodeSandbox&logoColor=white" alt="VNC Viewer" style="height: 25px;"/> &nbsp;
<img src="https://img.shields.io/badge/ROS-22314E.svg?&style=flat-square&logo=ros&logoColor=white" alt="ROS" style="height: 25px;"/> &nbsp;
<img src="https://img.shields.io/badge/RVIZ-000000.svg?&style=flat-square&logo=ros&logoColor=white" alt="RViz" style="height: 25px;"/> &nbsp;
<img src="https://img.shields.io/badge/Numpy-013243.svg?&style=flat-square&logo=numpy&logoColor=white" alt="Numpy" style="height: 25px;"/> &nbsp;
<img src="https://img.shields.io/badge/VS%20Code-007ACC.svg?&style=flat-square&logo=visual-studio-code&logoColor=white" alt="VS Code" style="height: 25px;"/> &nbsp;

<p align="center"><h2>▸ What is YdLidar:</h2></p>
<p style="text-align: justify;">
YdLiDAR is a type of Light Detection and Ranging (LiDAR) sensor designed for use in robotics and automation. LiDAR sensors measure distances by illuminating targets with laser light and measuring the reflection with a sensor. YdLiDAR sensors are known for their cost-effectiveness and compact size, making them suitable for applications like obstacle avoidance, area mapping, and robot navigation where precise distance measurements and environmental awareness are crucial. </p> <br>

<p align="center">
  <img src="readme_data/YDLidar.png" alt="YdLidar Sensor" width="220"/>
</p>

<p align="center"><h2>▸ How Does Lidar Work:</h2></p>
<p style="text-align: justify;">
TOF (Time of Flight) LiDAR is a technology that calculates the distance to a target by measuring the travel time of a light pulse. The process begins when a laser transmitter emits a beam of modulated light. This light travels to the target, bounces back, and is then detected by the laser receiver in the LiDAR system.

The core of TOF LiDAR's functionality lies in its ability to discern the phase difference between the light sent out and the light that returns. By accurately measuring this phase shift, the system can calculate the precise distance to the object with remarkable accuracy, making TOF LiDAR an essential tool for detailed spatial measurements and mapping.
</p>

<div align="center">
  <table>
    <tr>
      <td rowspan="2"><img src="readme_data/lidarscan.gif" alt="Lidar Scan" width="350"/></td>
      <td><img src="readme_data/tof_1.png" alt="TOF 1" width="525"/></td>
    </tr>
    <tr>
      <td><img src="readme_data/tof_2.jpg" alt="TOF 2" width="525"/></td>
    </tr>
  </table>
</div>

<!------ Deployment and Testing ------>
<p align="center"><h2>💠 Deployment and Testing</h2></p>
<p style="text-align: justify;">
▸ During the deployment and testing phase, the mobile robot was equipped with the aforementioned tools and sensors, which facilitated the implementation of the project. By integrating these technologies, the robot was able to perform autonomous navigation and obstacle avoidance. 

▸ The real-world performance of the robot was validated by plotting a 2D scan of its environment, which was then visualized in the rviz tool. This visualization provided a clear and detailed representation of how the robot perceives and interacts with its surroundings, demonstrating the effectiveness of the technologies in practical scenarios.
</p>

<p align="center">
  <img src="readme_data/project_observation_1.png" alt="Project Observation 1" width="1111"/>
</p>

<!------ End Image ------>
<p align="center">
  <img src="readme_data/project_observation_2.png" alt="Project Observation 2" width="1111"/>
</p> <hr> <br>

<!------ End Image ------>
<p align="center">
    <img src="readme_data/HKbot_endquote.png" alt="Alt text for your image" width="1500"/>
</p>
